import logging
import os
import speech_recognition as sr
from aiogram import Bot, Dispatcher, types
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters import Command
from pydub import AudioSegment
from aiogram.types import ReplyKeyboardRemove, ReplyKeyboardMarkup, KeyboardButton

logging.basicConfig(level=logging.INFO)
input_text = False

bot_token = ''
bot = Bot(token=bot_token)
storage = MemoryStorage()
dp = Dispatcher(bot, storage=storage)

menu_markup = ReplyKeyboardMarkup([[KeyboardButton(text='üìù –í–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç')]],
                                  one_time_keyboard=True,
                                  resize_keyboard=True,
                                  )

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—É-—Ö–µ–Ω–¥–ª–µ—Ä /start
@dp.message_handler(Command("start"))
async def cmd_start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –æ—Ç–ø—Ä–∞–≤–ª—é —Ç–µ–±–µ –µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤—É—é –≤–µ—Ä—Å–∏—é.\n\n"
        "–ß—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –Ω–∞–∂–º–∏ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è.\n\n"
        "–ß—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –Ω–∞–∂–º–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É.\n\n"
        "–û–∂–∏–¥–∞—é —Ç–≤–æ–∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ –∏ —Å–æ–æ–±—â–µ–Ω–∏—è!",
        reply_markup=menu_markup
    )

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ö–µ–Ω–¥–ª–µ—Ä –Ω–∞ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
@dp.message_handler(content_types=types.ContentType.VOICE)
async def handle_voice_message(message: types.Message, state: FSMContext):
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    voice = message.voice
    file_id = voice.file_id
    file_unique_id = voice.file_unique_id
    file = await bot.get_file(file_id)
    file_path = file.file_path

    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç WAV
    file_name = f"{file_unique_id}.oga"
    await bot.download_file(file_path, file_name)
    wav_file_name = f"{file_unique_id}.wav"
    convert_to_wav(file_name, wav_file_name)

    await message.answer(f"–ê—É–¥–∏–æ –ø–æ–ª—É—á–µ–Ω–æ, –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞...\n"
                         f"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è!")

    transcription = transcribe_audio(wav_file_name)

    await message.reply(f"{transcription}")

    os.remove(file_name)
    os.remove(wav_file_name)

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ö–µ–Ω–¥–ª–µ—Ä –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
@dp.message_handler()
async def echo_message(message: types.Message):
    global input_text
    if message.text == 'üìù –í–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç':
        await message.answer(f"–í–≤–µ–¥–µ–Ω–Ω—ã–π –≤–∞–º–∏ –¥–∞–ª–µ–µ —Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n"
                             f"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è!")
        input_text = True
    elif input_text:
        await message.answer(f"–í—ã –≤–≤–µ–ª–∏:\n\n{message.text}")
        input_text = False

def convert_to_wav(input_file, output_file):
    audio = AudioSegment.from_file(input_file)
    audio.export(output_file, format='wav')

def transcribe_audio(file_name):
    recognizer = sr.Recognizer()
    with sr.AudioFile(file_name) as source:
        audio = recognizer.record(source)
    try:
        transcription = "–¢–µ–∫—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è:\n\n" + recognizer.recognize_google(audio, language="ru-RU")
        return transcription
    except sr.UnknownValueError:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"
    except sr.RequestError:
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ —Å–µ—Ä–≤–∏—Å—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"

if __name__ == '__main__':
    from aiogram import executor
    executor.start_polling(dp, skip_updates=True)
